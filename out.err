2025-05-14 19:35:31.388508: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-14 19:35:31.450674: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-14 19:35:32.320925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/opt/conda/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
You shouldn't move a model that is dispatched using accelerate hooks.
Reading dataset:   0%|          | 0/20 [00:00<?, ?it/s]Reading dataset:   5%|▌         | 1/20 [00:00<00:13,  1.39it/s]Reading dataset:  10%|█         | 2/20 [00:01<00:09,  2.00it/s]Reading dataset:  15%|█▌        | 3/20 [00:01<00:07,  2.33it/s]Reading dataset:  20%|██        | 4/20 [00:01<00:06,  2.38it/s]Reading dataset:  25%|██▌       | 5/20 [00:02<00:09,  1.66it/s]Reading dataset:  30%|███       | 6/20 [00:03<00:07,  1.85it/s]Reading dataset:  35%|███▌      | 7/20 [00:03<00:06,  2.03it/s]Reading dataset:  40%|████      | 8/20 [00:04<00:06,  1.81it/s]Reading dataset:  45%|████▌     | 9/20 [00:05<00:07,  1.49it/s]Reading dataset:  50%|█████     | 10/20 [00:05<00:05,  1.69it/s]Reading dataset:  55%|█████▌    | 11/20 [00:05<00:04,  1.91it/s]Reading dataset:  60%|██████    | 12/20 [00:06<00:04,  1.72it/s]Reading dataset:  65%|██████▌   | 13/20 [00:07<00:04,  1.54it/s]Reading dataset:  70%|███████   | 14/20 [00:07<00:03,  1.74it/s]Reading dataset:  75%|███████▌  | 15/20 [00:08<00:02,  1.70it/s]Reading dataset:  80%|████████  | 16/20 [00:09<00:02,  1.58it/s]Reading dataset:  85%|████████▌ | 17/20 [00:10<00:02,  1.46it/s]Reading dataset:  90%|█████████ | 18/20 [00:10<00:01,  1.66it/s]Reading dataset:  95%|█████████▌| 19/20 [00:11<00:00,  1.64it/s]Reading dataset: 100%|██████████| 20/20 [00:11<00:00,  1.74it/s]Reading dataset: 100%|██████████| 20/20 [00:11<00:00,  1.73it/s]
/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:2347: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.
  warnings.warn(
Traceback (most recent call last):
  File "/home/jovyan/project/feature-extractor/main.py", line 37, in <module>
    main()
  File "/home/jovyan/project/feature-extractor/main.py", line 32, in main
    retrieval(args)
  File "/home/jovyan/project/feature-extractor/main.py", line 20, in retrieval
    model.generate(**query_tokens, max_new_tokens=512)
  File "/opt/conda/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py", line 2465, in generate
    result = self._sample(
  File "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py", line 3431, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 823, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 549, in forward
    layer_outputs = decoder_layer(
  File "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 259, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/opt/conda/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 225, in forward
    return self.weight * hidden_states.to(input_dtype)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1!
